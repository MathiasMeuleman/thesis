\chapter{Related work}\label{chap:related-work}

%\section{A short review of OMR}\label{sec:related-work-OMR}

\section{Existing datasets}\label{sec:related-work-existing-datasets}
When working with written music score data, there are a few datasets already available in the OMR field. Examples are the CVC-MUSCIMA \citep{Fornes2012} and its derivative, the MUSCIMA++ \citep{Hajic2017} for handwritten data, mainly aimed at staff line removal and symbol classification, and the MeasureBoundingBoxAnnotations dataset \citep{Zalkow2019}. Both the MUSCIMA++ and version 2 of the MeasureBoundingBoxAnnotations datasets have annotations for bounding boxes of individual measures.

\section{Measure detectors}
\begin{itemize}
    \item Otsu 1979 \citep{Otsu1979} binarization technique

    \item Bainbridge 2001 \citep{Bainbridge2001} Staff line detection through horizontal projections, possibly only on start and end of staff line to avoid noise through music symbols.

    \item Staff line height and staff space height determined through run-length encoding \citep{Rebelo2012}

    \item Dalitz 2008 \citep{Dalitz2008} Comparing several staff removal algorithms, which are implemented in the Gamera toolkit.

    \item Vigliensoni 2013 \citep{Vigliensoni2013} Optical measure recognition technique described. Staff detection is taken from \citep{} and barline detection is developed by the authors.
\end{itemize}
%\textit{From Google Doc} The segmenter currently embedded in the OMR pipeline is the one taken from the work of Waloschek, Hadjakos and Pacha [1]. Their approach consisted of manually annotating measures on pages of orchestral scores, defining a distance metric between annotated measures and training a CNN to detect measures in new input data. There are a few shortcomings to this approach. First of all, this model is far from perfect and makes too many mistakes to be used in a reasonable manner in this OMR pipeline. Even on pages that contain high quality scans and straight barlines, the detection is not perfect and therefore requires post-processing, see Figure 1 for two examples. Second, the measures that are detected are restricted to separation over time only. This means that when applying this to music scores with multiple instruments or voices -which is common in orchestral music, choir music, or piano scores- the segmenter will only segment horizontally, but leaves the different voicings grouped together in the same block. Besides this, the model is fixed and cannot be easily improved upon. Retraining the model to overcome the mistakes it currently makes would require manual annotation of these pages which is a very costly process. Finally, this model is relatively slow compared to other approaches. \issue{Insert mentions of \citep{Zalkow2019}}

\section{Dynamic Time Warping}
\begin{itemize}
    \item Senin 2008 \citep{Senin2008} Dynamic Time Warping overview, basic algorithm, customizations and optimizations with some examples.
\end{itemize}

\section{Similarity finding / clustering}
\begin{itemize}
    \item Niennattrakul 2006 \citep{Niennattrakul2006} Clustering multimedia data with time series. Comparing Euclidean and Dynamic Time Warping distances in a k-mediods clustering algorith.
    \item Niennattrakul 2007 \citep{Niennattrakul2007} Same topic as previous paper, but now showing why k-means is inferior to k-mediods clustering when using DTW measure as distance metric.
\end{itemize}

